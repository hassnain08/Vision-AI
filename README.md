# ğŸ§  Vision AI â€“ Real-Time Visual Assistant

**Vision AI** is an intelligent screen-reading assistant that sees whatâ€™s on your screen, understands your questions, and gives you spoken answers â€” all in real time.

Ask questions like:
- *â€œWhatâ€™s happening on this screen?â€*
- *â€œHow do I fix this error?â€*
- *â€œSummarize this article for meâ€*

â€¦ and Vision AI will analyze the visual context and respond â€” **out loud and in writing**.

> ğŸš€ Think of it as a smart teammate always looking over your shoulder â€” ready to help when youâ€™re stuck, curious, or just need a quick explanation.

---

## ğŸ¯ What It Does

Vision AI combines **screen capture**, **multimodal AI**, and **text-to-speech** to create an assistant that:
- Captures your current screen
- Analyzes it using **Googleâ€™s Gemini Flash** (vision + language model)
- Responds to your voice or text prompts
- Speaks the answer aloud using natural-sounding audio

Perfect for:
- Accessibility tools
- Learning aids
- Debugging support
- Productivity enhancement

---

## ğŸ› ï¸ Tech Stack

| Layer       | Technology |
|------------|-----------|
| Backend    | Python, Flask |
| AI Model   | Google Gemini Flash (multimodal) |
| Vision     | Screenshot capture via `mss` |
| Speech     | `gTTS` (Google Text-to-Speech), Web Speech API |
| Frontend   | HTML, CSS, Vanilla JavaScript |
| Environment| `.env` + `python-dotenv` |

---

## ğŸ–¼ï¸ How It Works

1. **ğŸ“¸ Capture**: Takes a screenshot of your primary monitor
2. **ğŸ§  Analyze**: Sends the image + your prompt to Gemini AI
3. **ğŸ’¬ Respond**: Gets a natural language answer
4. **ğŸ”Š Speak**: Converts the response to speech and plays it
5. **ğŸ–±ï¸ Interface**: Clean, floating-button UI for voice input and feedback

All powered locally with a simple web interface.

---
